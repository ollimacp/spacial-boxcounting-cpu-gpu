{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spacial boxcount algorithm and translation into convolutional neural network\n",
    "\n",
    "Ole Peters\n",
    "    \n",
    "## 1 Abstract\n",
    "\n",
    "This paper containes the postulation of a spacial boxcount algorithm, which characterizes any incoming 2D array spacially by tolological complexity and spacial heterogenit at diffrent scales. This characterizing allows spacial similarity search, spacial sorting capability, edge detection with userspecified scaled frequency bands, statistical analysis of input dataset.\n",
    "By training a convolutional neural network to mimik the cpu driven function the process can be speedup by a huge factor utilizing the parallel capability of a graphics card. \n",
    "\n",
    "## 2 Introduction\n",
    "\n",
    "The daily advances in machine learning establishes technological advances in almost any area of research. \n",
    "\n",
    "\n",
    "Box counting is a method of analyzing and soforth gather data by breaking data into boxes at diffrent scales and counting every filled box for each scale.\n",
    "\n",
    "\n",
    "Lacunarity is a mathematical discription for spacial heterogenity at a chosen scale.\n",
    "\n",
    "\n",
    "\n",
    "## 3 Experimental Setup and Methods\n",
    "\n",
    "In this paper a boxcount algorithm is proposed which can characterize data spacially in topological complexity and heterogenity.\n",
    "\n",
    "This algorithm enables characterizing, sorting and searching for spacial similarity for any kind of input data. Here pictures of diffrent topologies formed in a process of laser induced periodic surface structures(LIPSS) were used to demonstrate the algorithms capability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prequesits:\n",
    "#!pip -V     #executed as a bash command\n",
    "#ATTENTION if you use python3.9 numba will not work, so comment every line with 'numba' and 'jit' out\n",
    "#!pip install numpy numba pillow tqdm matplotlib\n",
    "# install pytorch with gpu support for local cuda version 11.0... modify as needed \n",
    "#  https://varhowto.com/install-pytorch-1-6-0/\n",
    "# !pip install torch===1.7.0+cu110 torchvision===0.8.1+cu110 torchaudio===0.7.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "#  if there is no CUDA capable GPU just install cpu version\n",
    "# !pip install torch==1.6.0+cpu torchvision==0.7.0+cpu -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "\n",
    "#Imports------------------------------------------------------------------------------------------\n",
    "import numpy as np # Python package for numeric computation\n",
    "import matplotlib.pyplot as plt # Python plotting libary for visualizing graphs, data and images\n",
    "\n",
    "#%matplotlib inline  #just used in jupyter, so the plots are actually shown\n",
    "\n",
    "import time\n",
    "import os\n",
    "from os import listdir\n",
    "\n",
    "#Importing nessecary modules for creating machine learning networks, such as \n",
    "import torch                                    #Pytorch machine learning framework.\n",
    "import torch.nn as nn                           #\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "#from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import math\n",
    "#import BoxcountFeatureExtr\n",
    "import sklearn.preprocessing as preprocessing\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials  #hyperoptimization libary\n",
    "\n",
    "\n",
    "# Common Directories\n",
    "import pathlib              #Import pathlib to create a link to the directory where the file is at.\n",
    "#just has to be specified in jupyter, if executed via the terminal __file__ is been found\n",
    "__file__ = 'Spacial Boxcount algorithm CPU and GPU.ipynb'    # Just use this when  __file__ is not been found\n",
    "\n",
    "FileParentPath = str(pathlib.Path(__file__).parent.absolute()) # Variable for path, where this file is in!\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If something goes wrong just use the PrintExeption() function to get all neccesary data\n",
    "import linecache\n",
    "import sys\n",
    "\n",
    "def PrintException():\n",
    "    exc_type, exc_obj, tb = sys.exc_info()\n",
    "    f = tb.tb_frame\n",
    "    lineno = tb.tb_lineno\n",
    "    filename = f.f_code.co_filename\n",
    "    linecache.checkcache(filename)\n",
    "    line = linecache.getline(filename, lineno, f.f_globals)\n",
    "    print('EXCEPTION IN ({}, LINE {} \"{}\"): {}'.format(filename, lineno, line.strip(), exc_obj))\n",
    "    \n",
    "    \n",
    "#Helper-function to show any np.array as a picture with a chosen title and a colormapping \n",
    "def showNPArrayAsImage(np2ddArray, title, colormap):\n",
    "    plt.figure()                    #Init figure\n",
    "    plt.imshow(np2ddArray,          #Gererate a picture from np.array and add to figure\n",
    "            interpolation='none',\n",
    "            cmap = colormap)\n",
    "    plt.title(title)                #Add title to figure\n",
    "    plt.show(block=False)           #Show array as picture on screen, but dont block the programm to continue.\n",
    "\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numba translates Python functions to optemized machine code at runtime\n",
    "#and results in significant speedups\n",
    "from numba import jit\n",
    "\n",
    "@jit(nopython= True) # Set \"nopython\" mode for best performance, equivalent to @njit\n",
    "def Z_boxcount(GlidingBox, boxsize,MaxValue):\n",
    "    '''\n",
    "    This function takes a np.array, boxsize and a maximum value for the z-direction\n",
    "    to return the counted boxes and the spacial lacunarity within this tower.\n",
    "    '''\n",
    "    \n",
    "    continualIndexes = GlidingBox/boxsize  \n",
    "    #print(continualIndexes)\n",
    "    Boxindexes = np.floor(continualIndexes)\n",
    "    #print(\"Boxindex\",Boxindexes)\n",
    "    unique_Boxes = np.unique(Boxindexes)\n",
    "    counted_Boxes = len(unique_Boxes)\n",
    "    #print(\"counted_Boxes\",counted_Boxes)\n",
    "\n",
    "    #CREATE  List of AnzPixInBox for all boxes to calc lacunarity\n",
    "    InitalEntry = [0.0]\n",
    "    AnzPixInBox = np.array(InitalEntry)\n",
    "\n",
    "    #For tiny boxes it can be process Consuming\n",
    "    for unique_BoxIndex in unique_Boxes:\n",
    "        #print(\"unique_BoxIndex\",unique_BoxIndex)\n",
    "        ElementsCountedTRUTHTABLE = Boxindexes == unique_BoxIndex\n",
    "        #print(\"ElementsCountedTRUTHTABLE\",ElementsCountedTRUTHTABLE)\n",
    "\n",
    "        ElementsCounted = np.sum(ElementsCountedTRUTHTABLE)\n",
    "        #print(\"ElementsCounted\",ElementsCounted)\n",
    "        AnzPixInBox = np.append(AnzPixInBox, ElementsCounted)\n",
    "\n",
    "    Max_Num_Boxes = int(MaxValue/ boxsize)\n",
    "    #print(\"Max_Num_Boxes\",Max_Num_Boxes)\n",
    "    Num_empty_Boxes = Max_Num_Boxes- counted_Boxes\n",
    "    \n",
    "    if Num_empty_Boxes <1:\n",
    "        #print(\"Num_empty_Boxes\",Num_empty_Boxes)\n",
    "        #EmptyBoxes = np.array([])\n",
    "        pass\n",
    "    else:\n",
    "        EmptyBoxes = np.zeros(Num_empty_Boxes)\n",
    "        AnzPixInBox = np.append(AnzPixInBox, EmptyBoxes)\n",
    "\n",
    "    mean = np.mean(AnzPixInBox)\t # berechnet den mittelwert der Summe der AnzahlDatenpunkteinboxen\n",
    "    #print(\"mean\",mean)\n",
    "\n",
    "    standardDeviation = np.std(AnzPixInBox) # berechnet die standartabweichung der Summe der AnzahlDatenpunkteinboxen der größe \n",
    "    #print(\"standardDeviation\",standardDeviation)\n",
    "\n",
    "    spacial_Lacunarity=np.power(standardDeviation/mean,2)\n",
    "    #print(\"die Lacunarity ist\", spacial_Lacunarity)\n",
    "\n",
    "    return counted_Boxes, spacial_Lacunarity\n",
    "\n",
    "\n",
    "@jit(nopython= True) #äFalse,forceobj=True) # Set \"nopython\" mode for best performance, equivalent to @njit\n",
    "def spacialBoxcount(npOutputFile, iteration,MaxValue):\n",
    "    '''\n",
    "    This function takes in a 2D np.array the iteration which determins the boxsize\n",
    "    and the maximum possible value to clip the value range. 8-Bit -> 256, hexadez ->16\n",
    "    \n",
    "    The function returns a 2 channel-2d array containing the spacial boxcountratio and the\n",
    "    spacial lacunarity scaled down in size by 1/Boxsize[iteration]\n",
    "    '''\n",
    "    Boxsize=[2,4,8,16,32,64,128,256,512,1024]\n",
    "\n",
    "    #MaxValueinArray = np.amax(npOutputFile)\n",
    "    #print(\"Max Value in Array is \",MaxValueinArray,\"!\")\n",
    "    #print(\"Current Boxsize is: \", Boxsize[iteration ],\" in Iteration \", iteration)\n",
    "    #input(\"Boxsize cannot be larger than filedepthness\")\n",
    "    #ATTENTION: BOXBOUNDRIES CANT BE BIGGER THEN min Dim height of input\n",
    "    # like: serialzed hex to bin  with  values from 0-16 -> max Boxsize = 16 -> max iteration =4\n",
    "\n",
    "\n",
    "    boxsize = Boxsize[iteration]\n",
    "\n",
    "    #Initialisiere unten Links vorne in der Ecke bei x=0,y=0 und z=0\n",
    "    BoxBoundriesX = np.array([0,Boxsize[iteration]])\n",
    "    BoxBoundriesY = np.array([0,Boxsize[iteration]])\n",
    "\n",
    "    Boxcount = 0\n",
    "    YRange, XRange  = npOutputFile.shape\n",
    "    #print( \"XRange, YRange\", XRange, YRange)\n",
    "\n",
    "    maxIndexY = YRange / boxsize \n",
    "    maxIndexY = int(maxIndexY)+1\n",
    "\n",
    "    maxIndexX = XRange / boxsize \n",
    "    maxIndexX = int(maxIndexX)+1\n",
    "    #print(\"maxIndexX: \",maxIndexX,\"maxIndexY: \",maxIndexY)\n",
    "    #BoxCountR_map = np.zeros((maxIndexX+1,maxIndexY+1))\n",
    "    #print(\"BoxCountR_map\",BoxCountR_map.shape)\n",
    "    #spa_Lac_map = np.zeros((maxIndexX+1,maxIndexY+1))\n",
    "    #print(\"spa_Lac_map\",spa_Lac_map.shape)\n",
    "    \n",
    "    \n",
    "    #Initialize the BoxcountRatio_map and spacial_lacunarity_map with zeros in correct shape\n",
    "    BoxCountR_map = np.zeros((maxIndexY,maxIndexX))\n",
    "    spa_Lac_map = np.zeros((maxIndexY,maxIndexX))\n",
    "\n",
    "\n",
    "    while BoxBoundriesY[1]<=YRange:\n",
    "\n",
    "        while BoxBoundriesX[1]<=XRange:\n",
    "            indexY = int(BoxBoundriesY[0]/boxsize)\n",
    "            indexX = int(BoxBoundriesX[0]/boxsize)\n",
    "\n",
    "            #print(\"indexX: \",indexX)\n",
    "            #print(\"indexY: \",indexY)\n",
    "\n",
    "            #print(\"BoxBoundriesX: \",BoxBoundriesX)\n",
    "            #print(\"BoxBoundriesY: \",BoxBoundriesY)\n",
    "            #The above answer is right but fails to explain what .reduceat is actually doing! basically it is returning the sum of the elements that lie in the sliced array\n",
    "            #AnzahlPixelIndieserBox=0\n",
    "\n",
    "            #Define Gliding box with Boundries 1 PIXEL Overlap ... for ex.  Boxsize 4  -> Boxboundries [0,4],[4,8] -> geht auf für n² wie in bildern etc und stitching is möglich\n",
    "            GlidingBox = npOutputFile[BoxBoundriesY[0]:BoxBoundriesY[1],BoxBoundriesX[0]:BoxBoundriesX[1]] \n",
    "\n",
    "            #print(\"GlidingBox: \", GlidingBox)\n",
    "            counted_Boxes, spacial_Lacunarity = Z_boxcount(GlidingBox, boxsize, MaxValue)\n",
    "            \n",
    "            #Despite counting the Boxes, the counts are normalized\n",
    "            #by the maximum possible counted boxes to get values from 0..1\n",
    "            #else the more little the boxsize the more boxes will be counted \n",
    "            Max_Num_Boxes = int(MaxValue/ boxsize)\n",
    "            counted_Box_Ratio = counted_Boxes / Max_Num_Boxes # ATTENTION \n",
    "\n",
    "\n",
    "            #print(\"counted_Boxes, spacial_Lacunarity.: \",counted_Boxes, spacial_Lacunarity)\n",
    "\n",
    "\n",
    "            BoxCountR_map[indexY,indexX] = counted_Box_Ratio\n",
    "            spa_Lac_map[indexY,indexX] = spacial_Lacunarity\n",
    "\n",
    "            # hat das boxende x noch nicht die volle XRange erreicht, so setze die box weiter \n",
    "            #move box into x direction\n",
    "            BoxBoundriesX[0]+=Boxsize[iteration]\n",
    "            BoxBoundriesX[1]+=Boxsize[iteration]\n",
    "\n",
    "\n",
    "        #VersetzeBoxZumStartX\n",
    "        BoxBoundriesX[0]=0\n",
    "        BoxBoundriesX[1]=Boxsize[iteration]\n",
    "        #BoxBoundriesY = VersetzeBoxnachY(BoxBoundriesY, iteration)\n",
    "        BoxBoundriesY[0]+=Boxsize[iteration]\n",
    "        BoxBoundriesY[1]+=Boxsize[iteration]\n",
    "\n",
    "\n",
    "    BoxCountR_SpacialLac_map = [BoxCountR_map, spa_Lac_map]\n",
    "\n",
    "    #print(BoxCountR_map)\n",
    "    #print(spa_Lac_map)\n",
    "    #print(\"Iteration \", iteration, \"calculation done\")\n",
    "\n",
    "    return BoxCountR_SpacialLac_map\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def MultithreadBoxcount(npOutputFile):\n",
    "    \n",
    "    '''\n",
    "    To gain another speedup in the sequencial generated output, multithreading is used\n",
    "    to calculate the spacial Boxcountratios/lacunaritys for each boxsize in a own thread.\n",
    "    \n",
    "    '''\n",
    "\n",
    "    start = time.time()\n",
    "\n",
    "    #MULTICORE APROACH\n",
    "    #print(\"Beginn Multithread Boxcount Lacunarity feature extraction\")\n",
    "    BoxsizeDict={\"2\":0 ,\"4\":1,\"8\":2,\"16\":3,\"32\":4,\"64\":5,\"128\":6,\"256\":7,\"512\":8,\"1024\":9}\n",
    "\n",
    "    #Cut to lenght\n",
    "    Height , width = npOutputFile.shape\n",
    "    Height , width = int(Height) , int(width) \n",
    "    BaseITERMinVal = min(16,Height , width  )\n",
    "    BaseIteration = BoxsizeDict[str(int(BaseITERMinVal))] #without 0 there are 1 more processes \n",
    "    #print(\"BaseIteration = NumberOfThreads: \",BaseIteration)\n",
    "    maxiteration =  BaseIteration +1    # to calc Lacunarity there have to be more than just one box into the z direction\n",
    "    #print(\"maxiteration, cause 0 counts: \",maxiteration)\n",
    "\n",
    "    #https://stackoverflow.com/questions/6893968/how-to-get-the-return-value-from-a-thread-in-python\n",
    "\n",
    "    def BoxcountBoxsizeWorker(npOutputFile, iteration):\n",
    "        #print(\"Boxcount/Lac in Iteration \",iteration,\" started\")\n",
    "        #print(\"Max Value is \", DataObject.max_Value )\n",
    "        maxvalue = 256  # cause zheight is 0...255\n",
    "        BoxCountR_SpacialLac_map = spacialBoxcount(npOutputFile, iteration,maxvalue )     \n",
    "        #print(\"BoxCountR_SpacialLac_map)\",BoxCountR_SpacialLac_map)\n",
    "        #print(\"type)\",type(BoxCountR_SpacialLac_map))\n",
    "        #print(\"len)\",len(BoxCountR_SpacialLac_map))\n",
    "        #print(\"Iteration \",iteration,\" DOne\")\n",
    "\n",
    "        return BoxCountR_SpacialLac_map\n",
    "\n",
    "    from threading import Thread\n",
    "\n",
    "    class ThreadWithReturnValue(Thread):\n",
    "        def __init__(self, group=None, target=None, name=None,\n",
    "                    args=(), kwargs={}, Verbose=None):\n",
    "            Thread.__init__(self, group, target, name, args, kwargs)\n",
    "            self._return = None\n",
    "        def run(self):\n",
    "            #print(type(self._target))\n",
    "            if self._target is not None:\n",
    "                self._return = self._target(*self._args,\n",
    "                                                    **self._kwargs)\n",
    "        def join(self, *args):\n",
    "            Thread.join(self, *args)\n",
    "            return self._return\n",
    "\n",
    "\n",
    "\n",
    "    threads = [None] * maxiteration      \n",
    "    #print(\"maxiteration =\",maxiteration)      \n",
    "    start = time.time()\n",
    "\n",
    "\n",
    "    for i in range(len(threads)):\n",
    "        threads[i] = ThreadWithReturnValue(target=BoxcountBoxsizeWorker, args=(npOutputFile, i))\n",
    "        threads[i].start()\n",
    "        #print(\"thread \",i+1,\" has started\")\n",
    "        #FOR LATER maybe: IF Boxcount (i=0 or 1)  split the np outputfile into 4 and start 4 threads and combine the maps later\n",
    "\n",
    "    # do some other stuff\n",
    "    #BoxCountR_SpacialLac_map_List = np.array([])\n",
    "    BoxCountR_SpacialLac_map_Dict = {\"iteration\": np.array([\"BoxcountRatio\",\"spacialLacunarity\"]) }\n",
    "    for i in range(len(threads)):\n",
    "        #print(\"joining Thread \",i)\n",
    "        BoxCountR_SpacialLac_map = np.array(threads[i].join())\n",
    "        #print(BoxCountR_SpacialLac_map)\n",
    "        #print(BoxCountR_SpacialLac_map.shape)\n",
    "        #print(type(BoxCountR_SpacialLac_map))\n",
    "        #input()\n",
    "        #BoxCountR_SpacialLac_map_List = np.append(BoxCountR_SpacialLac_map_List, [BoxCountR_SpacialLac_map] )\n",
    "        BoxCountR_SpacialLac_map_Dict[i]= BoxCountR_SpacialLac_map\n",
    "\n",
    "        #print(\"Thread \",i,\" JOINED\")\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(end - start,\"s brauchte die fraktale Berechnung für eine Datei mit\",i+1, \"Iterationen/Skalierungen\")\n",
    "    return BoxCountR_SpacialLac_map_Dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def Show_Pictures():\n",
    "\n",
    "    maxSamplesize = 256\n",
    "    #DensityMap= np.array([[0.0,0.0],])\n",
    "    maxSamplesize = 256\n",
    "\n",
    "    maxIndexX, maxIndexY = maxSamplesize, maxSamplesize\n",
    "    shape = (maxIndexX, maxIndexY )\n",
    "\n",
    "    from os import listdir\n",
    "    DataFolder = FileParentPath + \"/0Data/Auswahl/\"\n",
    "    filelist = [f for f in listdir(DataFolder)]\n",
    "    print(DataFolder)\n",
    "\n",
    "    n = 4 # werden wohl bis max 16 begrenzen # ist 4 da beim slicen  richitg wäre  boxsize[:4] oder [:-7]   \n",
    "    print(\"begin enumerating files\")\n",
    "    for index, filename in enumerate(filelist):\n",
    "        #pbar.update(1)  #updates progressbar\n",
    "        #counter +=1\n",
    "        try:   \n",
    "            start = time.time()\n",
    "            filepath = DataFolder+ filename \n",
    "            print(filename)\n",
    "            #Load Image with Pillow\n",
    "            #load x,y,...,R,G,B ...,YCMK  -> defining dimensionality\n",
    "            #Pack every Data onto an MpM Array\n",
    "            #return Codierung(Format:pic,Dim:[x,y,R,G,B]) , 3D MpM  Data np array\n",
    "            # load and show an image with Pillow\n",
    "            # Open the image form working directory\n",
    "            image = Image.open(filepath)\n",
    "            # summarize some details about the image\n",
    "            print(image.format,image.size)\n",
    "            #print(image.mode)\n",
    "            # show the image\n",
    "            #image.show()\n",
    "            \n",
    "            ChannleDimension = len(str(image.mode)) # grey -> 1 chan , rgb 3 channle\n",
    "            #print(\"ChannleDimension\",ChannleDimension)\n",
    "            \n",
    "            channelcodierung = []\n",
    "            for channel in image.mode:\n",
    "                #FLATTEN EACH CHANNEL TO ONE  BY TILING, cause cnn have to be consistent channles\n",
    "                #and if one rgb is in grayscale, then error\n",
    "                channelcodierung.append(channel)\n",
    "            #print(channelcodierung)    \n",
    "            \n",
    "            C1 = None\n",
    "            C2 = None\n",
    "            C3 = None\n",
    "            C4 = None\n",
    "            C5 = None\n",
    "            C6 = None\n",
    "\n",
    "            channellist = [C1,C2,C3,C4,C5,C6]\n",
    "            croppedChannelList = channellist[0:ChannleDimension-1]\n",
    "            croppedChannelList = image.split()        \n",
    "\n",
    "            initEntry = None\n",
    "            stackedchannels = np.array(initEntry)\n",
    "            #stackedchannels = None\n",
    "            for index, channel in enumerate(croppedChannelList):\n",
    "                #channel.show()  #print(channel)\n",
    "                PicNumpy = np.array(channel)\n",
    "                #print(PicNumpy)\n",
    "                #print(PicNumpy.shape)\n",
    "\n",
    "                if index == 0:\n",
    "                    stackedchannels = PicNumpy\n",
    "                else:\n",
    "                    stackedchannels = np.concatenate((stackedchannels,PicNumpy),axis=1)\n",
    "                    \n",
    "            #print(stackedchannels)\n",
    "            #print(stackedchannels.shape)\n",
    "            npOutputFile = stackedchannels\n",
    "            codierung = [\"x\",\"y\"]   # x and y for every pic in the world\n",
    "            codierung.append(channelcodierung) # grey (x,y,g) # RGB (x,y,R,G,B)\n",
    "\n",
    "            #########################################################################\n",
    "            # MULTITHREAD BOXCOUNT LABLE EXTRACTION\n",
    "            BoxCountR_SpacialLac_map_Dict = MultithreadBoxcount(npOutputFile)\n",
    "            \n",
    "            #feature =  npOutputFile\n",
    "            #label =  [) , np.array(BoxCountR_SpacialLac_map_Dict[1]) , np.array(BoxCountR_SpacialLac_map_Dict[2]) , np.array(BoxCountR_SpacialLac_map_Dict[3]) ]\n",
    "            #showNPArrayAsImage(label[1,:,:], \"label\", \"gray\")\n",
    "            #input()\n",
    "            #print(\"feature\",feature)\n",
    "            #print(\"label\",label)\n",
    "\n",
    "            end = time.time()     \n",
    "            print(round(end,1) - round(start,1), \"seconds passed while boxcounting for 1 File\")\n",
    "\n",
    "    \n",
    "            showNPArrayAsImage(npOutputFile, \"Original Picture\", \"gray\")\n",
    "            \n",
    "            BCRmap2 , Lakmap2 = BoxCountR_SpacialLac_map_Dict[0]\n",
    "            BCRmap4 , Lakmap4 = BoxCountR_SpacialLac_map_Dict[1]\n",
    "            BCRmap8, Lakmap8 = BoxCountR_SpacialLac_map_Dict[2]\n",
    "            BCRmap16 , Lakmap16 = BoxCountR_SpacialLac_map_Dict[3]\n",
    "\n",
    "            showNPArrayAsImage(BCRmap2, \"BCRmap2\", \"gray\")\n",
    "            showNPArrayAsImage(Lakmap2, \"Lakmap2\", \"gray\")\n",
    "            \n",
    "            showNPArrayAsImage(BCRmap4, \"BCRmap4\", \"gray\")\n",
    "            showNPArrayAsImage(Lakmap4, \"Lakmap4\", \"gray\")\n",
    "            \n",
    "            showNPArrayAsImage(BCRmap8, \"BCRmap8\", \"gray\")\n",
    "            showNPArrayAsImage(Lakmap8, \"Lakmap8\", \"gray\")\n",
    "            \n",
    "            showNPArrayAsImage(BCRmap16, \"BCRmap16\", \"gray\")\n",
    "            showNPArrayAsImage(Lakmap16, \"Lakmap16\", \"gray\")\n",
    "\n",
    "            #input()\n",
    "            \n",
    "            \n",
    "            \n",
    "        except :\n",
    "            PrintException()\n",
    "            input()\n",
    "            pass\n",
    "            #print(label, f, str(e))\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Show_Pictures()\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "QUOITE abstract:  This characterizing allows spacial similarity search, spacial sorting capability, edge detection with userspecified scaled frequency bands, statistical analysis of input dataset.\n",
    "SHOW HERE WHAT CAN BE DONE WITH THOSE SPACIAL BOXCOUNTS\n",
    "similarity search- input np array and use finder.py to identify similar pictures by sum(Boxcount(boxsize)) and scale importance by scalingfacor\n",
    "for example. search this part of a conestructure and boxsizescale = min, so we dont care about the fine structure\n",
    "\n",
    "extract Frequencys with fast fouier and filter higher freq with bigger boxes\n",
    "extracts counts from bumps in an picture by isolating them in lak8,26 and count eachisolated area\n",
    "\n",
    "loalize GAPs with lak and isolate diffrent scaled gaps\n",
    "\n",
    "identify outliars with statsitical comparison -> max lak.. failed measurement...  \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "GPU VERSION PART\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen device is cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "#Variables---------------------------------------------------\n",
    "ChunkLenght = 256  # The picture will be hacked into pieces of chosen Size -> more Datapoints, less Ram, ...\n",
    "\n",
    "maxIndexX, maxIndexY = ChunkLenght, ChunkLenght\n",
    "shape = (maxIndexX, maxIndexY )\n",
    "\n",
    "#BOXCOUNT INIT\n",
    "Boxsize=[2,4,8,16,32,64,128]    #,256,512,1024]\n",
    "iteration = 0\n",
    "#os.makedirs(\"images\", exist_ok=True)\n",
    "\n",
    "'''\n",
    "Import Argument Parser to train/test models with specific arguments.\n",
    "F.e: Convolutionalboxcountencoder.py --n_epochs=120 --batch_size=32 ...\n",
    "\n",
    "import argparse\n",
    "import BoxcountFeatureExtr\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--n_epochs\", type=int, default=100, help=\"number of epochs of training\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=16, help=\"size of the batches\")\n",
    "parser.add_argument(\"--lr\", type=float, default=0.00002, help=\"adam: learning rate\")\n",
    "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\n",
    "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\n",
    "parser.add_argument(\"--img_size\", type=int, default=ChunkLenght, help=\"size of each image dimension\")\n",
    "parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\n",
    "opt = parser.parse_args()\n",
    "print(opt)\n",
    "'''\n",
    "class OptionObject:\n",
    "  def __init__(self, n_epochs, batch_size, img_size, channels, learning_rate, b1, b2 ):\n",
    "    self.n_epochs = n_epochs\n",
    "    self.batch_size = batch_size\n",
    "    self.img_size = img_size\n",
    "    self.lr = learning_rate\n",
    "    self.b1 = b1   #first order momentum of gradient decay\n",
    "    self.b2 = b2   #second order momentum of gradient decay\n",
    "    self.channels = channels\n",
    "    \n",
    "opt = OptionObject(100, 32, ChunkLenght, 1 , 0.00002, 0.5, 0.8)\n",
    "img_shape = (opt.channels, opt.img_size, opt.img_size)\n",
    "\n",
    "\n",
    "\n",
    "#https://stackoverflow.com/questions/35751306/python-how-to-pad-numpy-array-with-zeros\n",
    "#@jit(nopython=False)  #,forceobj=True) # Set \"nopython\" mode for best performance, equivalent to @njit\n",
    "\n",
    "\n",
    "def pad(array, reference, offset):\n",
    "    \"\"\"\n",
    "    array: Array to be padded\n",
    "    reference: Reference array with the desired shape\n",
    "    offsets: list of offsets (number of elements must be equal to the dimension of the array)\n",
    "    \"\"\"\n",
    "    # Create an array of zeros with the reference shape\n",
    "    result = np.zeros(reference.shape)\n",
    "    # Create a list of slices from offset to offset + shape in each dimension\n",
    "    insertHere = [slice(offset[dim], offset[dim] + array.shape[dim]) for dim in range(array.ndim)]\n",
    "    # Insert the array in the result at the specified offsets\n",
    "    result[insertHere] = array\n",
    "    return result\n",
    "\n",
    "#If a picture/array is more little than the reference shape, than add zeros to the right and bottom with pad()-function to bring it into chunklenght x chunklenght\n",
    "\n",
    "def reshape_Data(PicNumPy,shape, original_shape):\n",
    "    print(\"reshaping, cause shape and original shape are\", shape, original_shape)\n",
    "    #if shape is bigger then original, set new max and retry making data\n",
    "    reshape = (int(original_shape[0]),int(original_shape[1]) )\n",
    "    print(\"reshape\",reshape )\n",
    "    print(\"PicNumPy shape\",PicNumPy.shape)\n",
    "    ### can add offset; so that pict can be centered\n",
    "    offset = [0,0,0]\n",
    "    PicNumPy = pad(PicNumPy,np.zeros(reshape),offset )\n",
    "    return PicNumPy\n",
    "\n",
    "\n",
    "\n",
    "def delete_dataset_from_last_time():\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "#Setting device to GPU/CPU \n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "\n",
    "    return device\n",
    "\n",
    "device = get_device()\n",
    "print(\"Chosen device is\",device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#https://discuss.pytorch.org/t/inferring-shape-via-flatten-operator/138/2\n",
    "# generate input sample and forward to get shape of the Convolutional Output\n",
    "def get_conv_output(self, shape):\n",
    "    #print(\"Calc conv output after forewardpassing\")\n",
    "    bs = 1\n",
    "    input = Variable(torch.rand( *shape))\n",
    "    #input = Variable(torch.rand( (16,1,256,256)))\n",
    "    self, output_feat = Conv_features(self, input)\n",
    "    #print(\"Convolution output_feat.shape\",output_feat.shape)\n",
    "    n_size = output_feat.data.view(bs, -1).size(1)\n",
    "    #print(\"Flattend into n_size\")\n",
    "    return n_size\n",
    "\n",
    "def Conv_features(self, x):\n",
    "    for i, layer in enumerate(self.Layers):        #iterate forwards\n",
    "        #IN,OUT, Kx, Ky,Sx,Sy,Px,Py,BN = self.LayerDiscription[i]\n",
    "        #print(\"Layer\",i)    #,\" with Parameters\", IN,OUT, Ky,Sx,Sy,Px,Py,BN)\n",
    "        #self.Layers[i] = nn.ConvTranspose2d(OUT, IN, kernel_size=(Kx, Ky), stride=(Sx, Sy), padding=(Px, Py))       #Attention ENhancer IN OUT Switched\n",
    "        \n",
    "        #print(\"Compression Layer\",i)\n",
    "        x = self.Layers[i](x)\n",
    "        #print(\"x.shape\",x.shape)\n",
    "    \n",
    "    return self, x\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Data Balancing/Reshaping Part-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "'''\n",
    "If rebuild  data == True, take the chosen Data and create atrain Data set from sigma-balanced  and 0-1 normalized and scaled gaußian distrubution and pack the test into the test set for maxemizing data-usage\n",
    "\n",
    "To create a machine learning dataset from scratch, the data has to be augmented to enable the network to learn the desired patterns.\n",
    "\n",
    "The data has to be balanced in multiple ways to prevent overfitting.\n",
    "For example not all pictures can be used to train data. Binary classes can be balanced just by taking 50/50 balance for the training dataset.\n",
    "Cause the lables are the calculated arrays of a cpu driven program, there is just a continuum of output arrays for input arrays.\n",
    "'''\n",
    "\n",
    "REBUILD_DATA = False  # set to true to run once, then back to false unless you want to change something in your training data.\n",
    "precision = 1   # 0 dont balance, 1 balance light, ...9 balance fine; The finer, the more data will be discarded\n",
    "\n",
    "\n",
    "#Funktions defines, if returns True, dataset stays balanced, so take into train-data, else pack into test set. \n",
    "#@jit(nopython=False)  #,forceobj=True) # Set \"nopython\" mode for best performance, equivalent to @njit\n",
    "def CalcPlacingcondition(DensityMap, sumBCR,sumLAK, precision, lastVariance, index):\n",
    "    '''\n",
    "    To balance the Data in an Dataset, the  mean BoxcountRatio(spacial complexity) and the mean lacunarity(spacial heterogenity) is used to\n",
    "    discribe/characterize any kind of data into 2D values (x,y). \n",
    "    The balanced dataset is achieved to approach the highest variance with all Elements of BoxcountRatio(spacial complexity) and lacunarity(spacial heterogenity).\n",
    "    Soforth the syntax is defined by initializing the distribution by adding the first few pictures to the training dataset\n",
    "    and calculate the variance of all containing elements.\n",
    "    Afterwards it just adds the new element to the training set have to increase the variance of the BCR and splac.\n",
    "    The discarded data is added to the test dataset for later testing.\n",
    "\n",
    "    To have some sort of controlling the agressiveness of the train/test splitting \n",
    "    the variable precision is used to round the old and new variance and if the new variance is the same of bigger\n",
    "    add the current picture/element to the training dataset. If precision is zero, don't balance in any way\n",
    "    '''\n",
    "    #print(\"DensityMap\",DensityMap)\n",
    "    print(\"DensityMap.shape\",DensityMap.shape)\n",
    "\n",
    "    element = np.array([[sumBCR,sumLAK],])\n",
    "    #np.reshape(element,(2,))\n",
    "    #print(element)\n",
    "    #print(\"element.shape\",element.shape)\n",
    "    \n",
    "    if index ==0:\n",
    "        combinedDensityMap = element     #init first element\n",
    "    else:\n",
    "        #concatenate the BCR and LAK from the current element to the \n",
    "        combinedDensityMap = np.concatenate((DensityMap,element),axis=0)\n",
    "\n",
    "        \n",
    "    if precision == 0:\n",
    "        placingcondition = True\n",
    "        DensityMap = combinedDensityMap\n",
    "        lastVariance = np.var(combinedDensityMap)\n",
    "\n",
    "    else:\n",
    "        if index <= 6:\n",
    "            #to populate the field, just add the first 6 elements\n",
    "            placingcondition = True\n",
    "\n",
    "            #cause element placingcondition is true, update the variances             \n",
    "            combinedVariance = np.var(combinedDensityMap)\n",
    "            lastVariance =  combinedVariance\n",
    "            print(\"populate with minimum Pop\")\n",
    "\n",
    "        else:\n",
    "            #calculate the Variance from this turn\n",
    "            combinedVariance = np.var(combinedDensityMap)\n",
    "\n",
    "            #if the rounded variance of this turn is more or the same of the variance last turn\n",
    "            if round(combinedVariance,precision) >= round(lastVariance,precision):    \n",
    "                placingcondition = True\n",
    "                #and update the last variance for next turn with the new value\n",
    "                lastVariance =  combinedVariance\n",
    "                DensityMap = combinedDensityMap\n",
    "\n",
    "            else:\n",
    "                #dont add this element to the training dataset but to the test dataset\n",
    "                placingcondition = False\n",
    "               \n",
    "        \n",
    "            \n",
    "\n",
    "            #print(\"index:\", index,\"    formerVariance,combinedVariance\",round(lastVariance,precision),round(combinedVariance,precision),\"so placing is\",placingcondition)    \n",
    "            #input()\n",
    "\n",
    "    return placingcondition, DensityMap, lastVariance\n",
    "\n",
    "\n",
    "\n",
    "def make_train_test_data(shape):\n",
    "    \n",
    "    Num_test = 0\n",
    "    Num_train = 0\n",
    "    firsttime = True\n",
    "\n",
    "    DensityMap= np.array([[0.0,0.0],])\n",
    "    lastVariance = 0.0\n",
    "    original_shape = shape\n",
    "\n",
    "    #For Visualizing  tqdm-progress bar\n",
    "    from tqdm import tqdm\n",
    "    pbar = tqdm(total=maxIndexY-1)\n",
    "    counter = 0\n",
    "    train_counter = 0\n",
    "    test_counter =0\n",
    "\n",
    "    from os import listdir\n",
    "    DataFolder = FileParentPath + \"/0Data/Auswahl/\"\n",
    "    filelist = [f for f in listdir(DataFolder)]\n",
    "    #print(filelist)\n",
    "\n",
    "\n",
    "\n",
    "    from tqdm import tqdm\n",
    "    pbar = tqdm(total=len(filelist))\n",
    "\n",
    "    \n",
    "    n = 4 # werden wohl bis max 16 begrenzen # ist 4 da beim slicen  richitg wäre  boxsize[:4] oder [:-7]   \n",
    "\n",
    "    for index, filename in enumerate(filelist):\n",
    "        pbar.update(1)  #updates progressbar\n",
    "        counter +=1\n",
    "        try:   \n",
    "            filepath = DataFolder+ filename  #Load Image with Pillow\n",
    "            \n",
    "            image = Image.open(filepath) # Open the image\n",
    "            \n",
    "            # summarize some details about the image\n",
    "            #print(image.format,image.size)\n",
    "            #print(image.mode)\n",
    "            # show the image\n",
    "            #image.show()\n",
    "            \n",
    "            # If the picture is in RGB or other mulichannel mode \n",
    "            #just seperate the channels and concatenate them from left to right\n",
    "            ChannleDimension = len(str(image.mode)) # grey -> 1 chan , rgb 3 channle\n",
    "            #print(\"ChannleDimension\",ChannleDimension)\n",
    "            \n",
    "            channelcodierung = []\n",
    "            for channel in image.mode:\n",
    "                #FLATTEN EACH CHANNEL TO ONE  BY TILING, cause cnn have to be consistent channles\n",
    "                #and if one rgb is in grayscale, then error\n",
    "                #print(channel)\n",
    "                channelcodierung.append(channel)\n",
    "\n",
    "            #print(channelcodierung)    \n",
    "            \n",
    "            C1, C2, C3, C4, C5, C6 = None, None, None, None, None, None\n",
    "\n",
    "            channellist = [C1,C2,C3,C4,C5,C6]\n",
    "\n",
    "            croppedChannelList = channellist[0:ChannleDimension-1]\n",
    "            croppedChannelList = image.split()        \n",
    "\n",
    "            initEntry = None\n",
    "            stackedchannels = np.array(initEntry)\n",
    "            #stackedchannels = None\n",
    "            for idx, channel in enumerate(croppedChannelList):\n",
    "                PicNumpy = np.array(channel)\n",
    "                #print(PicNumpy)\n",
    "                #print(PicNumpy.shape)\n",
    "\n",
    "                if idx == 0:\n",
    "                    stackedchannels = PicNumpy\n",
    "                else:\n",
    "                    stackedchannels = np.concatenate((stackedchannels,PicNumpy),axis=1)\n",
    "\n",
    "            #print(stackedchannels)\n",
    "            #print(stackedchannels.shape)\n",
    "            npOutputFile = stackedchannels\n",
    "\n",
    "            codierung = [\"x\",\"y\"]   # x and y for every pic in the world\n",
    "            codierung.append(channelcodierung) # grey (x,y,g) # RGB (x,y,R,G,B)\n",
    "\n",
    "\n",
    "            #########################################################################\n",
    "\n",
    "            # MULTITHREAD BOXCOUNT LABLE EXTRACTION\n",
    "            BoxCountR_SpacialLac_map_Dict = BoxcountFeatureExtr.MultithreadBoxcount(npOutputFile)\n",
    "\n",
    "            \n",
    "            \n",
    "            ##### CALC PLACING CONDITION FOR EACH DATAPOINT(PICTURE)\n",
    "            \n",
    "            maxiteration = 3 # cause boxsize 2,4,8,16 = 0,1,2,3 iteration\n",
    "            #just take the second smallest BCR and sumLAK for  calcing the mean and  so the dataset can be balanced\n",
    "            sumBCR, sumLAK = BoxCountR_SpacialLac_map_Dict[maxiteration-2][0], BoxCountR_SpacialLac_map_Dict[maxiteration-2][1]             #BoxCountR_SpacialLac_map_Dict[4] #[0], BoxCountR_SpacialLac_map_Dict[4][1] \n",
    "            #breaking it down to a single value\n",
    "            #print(\"BCR,sumLAK  MAP before sum\", sumBCR,sumLAK)\n",
    "\n",
    "            sumBCR, sumLAK = np.sum(sumBCR), np.sum(sumLAK)\n",
    "            print(\"sumBCR,sumLAK after sum\", sumBCR,sumLAK)\n",
    "            #float(sumBCR), int(sumLAK) = Read_corresponding_frac_parameter()\n",
    "            \n",
    "            #input()\n",
    "\n",
    "            #Calc, if the next data in the dataset will balance it more or not\n",
    "            placingcondition, DensityMap, lastVariance = CalcPlacingcondition(DensityMap, sumBCR,sumLAK,precision,lastVariance, index)\n",
    "\n",
    "            '''\n",
    "            Cause every Picture is diffrent sized and cause you're able to recognize a thing only looking parts of it and prevent VRAM overload during training cut the picture into chunks\n",
    "            if the chunks are not shaped consistent, pad the np-array with zeros upto the shape they belong. \n",
    "\n",
    "            '''\n",
    "            maxChunkCount = (npOutputFile.shape[1]/ChunkLenght) * (npOutputFile.shape[0]/ChunkLenght)   #Chunks the picture is broken down into\n",
    "            #print(\"maxChunkCount\", maxChunkCount)\n",
    "            Chunks = [None] * math.ceil(maxChunkCount)            \n",
    "            start = time.time()\n",
    "\n",
    "            BoxBoundriesY = [0,ChunkLenght]\n",
    "            BoxBoundriesX = [0,ChunkLenght]\n",
    "\n",
    "            iteration = 0       # is Boxsize 32 -> should be faster then more little boxsize\n",
    "            Boxsize=[2,4,8,16,32,64,128,256,512,1024]\n",
    "            scalingFaktor = 1.0 / float(Boxsize[iteration])\n",
    "            #If we take a sclice from the BCRmap/LAKmap, the boxboundries have to  be scaled for maintaining spacial dimensions across scaling with iteration and Boxsize\n",
    "            Scaled_BoxBoundriesY = [0,int(ChunkLenght*scalingFaktor)]\n",
    "            Scaled_BoxBoundriesX = [0,int(ChunkLenght*scalingFaktor)]\n",
    "\n",
    "\n",
    "            for i in range(len(Chunks)):\n",
    "                #print(\"Box\",i,\"of\",len(Chunks))\n",
    "                #print(\"Boxboundries: X, Y :\" ,BoxBoundriesX,BoxBoundriesY)\n",
    "                #PicNumPy = np.array(npOutputFile).astype(float)\n",
    "\n",
    "                Chunks[i] = npOutputFile[BoxBoundriesY[0]:BoxBoundriesY[1],BoxBoundriesX[0]:BoxBoundriesX[1]] \n",
    "\n",
    "                CHUNKED_BoxCountR_SpacialLac_map_Dict = {}\n",
    "                CuttedBoxsizeList = Boxsize[:maxiteration+1]\n",
    "                #print(\"CuttedBoxsizeList\", CuttedBoxsizeList)\n",
    "                #print(\"Converting BCRmap,LAKmap into Chunked Form\")\n",
    "                for it , currentboxsize in enumerate(CuttedBoxsizeList):\n",
    "                    #Alternativly Calc it again, but would be wasteful, try just indexing\n",
    "                    print(\"Iteration\", it, \" and currentBoxsize\", currentboxsize)\n",
    "                    \n",
    "                    scalingFaktor = 1.0 / float(currentboxsize)\n",
    "                    \n",
    "                    try:\n",
    "                        #calc Scaled BoxBoundriesY\n",
    "                        Scaled_BoxBoundriesY = [int(BoxBoundriesY[0]*scalingFaktor),int(BoxBoundriesY[1]*scalingFaktor)]\n",
    "\n",
    "                    except:\n",
    "                        PrintException()\n",
    "                        #Assuming devide by zero\n",
    "                        Scaled_BoxBoundriesY = [0,int(BoxBoundriesY[1]*scalingFaktor)]\n",
    "\n",
    "                    try:\n",
    "                        #calc Scaled BoxBoundriesX\n",
    "                        Scaled_BoxBoundriesX = [int(BoxBoundriesX[0]*scalingFaktor),int(BoxBoundriesX[1]*scalingFaktor)]\n",
    "\n",
    "                    except:\n",
    "                        PrintException()\n",
    "                        #Assuming devide by zero\n",
    "                        Scaled_BoxBoundriesX = [0,int(BoxBoundriesX[1]*scalingFaktor)]                       \n",
    "\n",
    "\n",
    "                    BCRmap, LAKmap = BoxCountR_SpacialLac_map_Dict[it]\n",
    "                    \n",
    "\n",
    "                    chunked_BCRmap = BCRmap[Scaled_BoxBoundriesY[0]:Scaled_BoxBoundriesY[1],Scaled_BoxBoundriesX[0]:Scaled_BoxBoundriesX[1]] \n",
    "                    chunked_LAKmap = LAKmap[Scaled_BoxBoundriesY[0]:Scaled_BoxBoundriesY[1],Scaled_BoxBoundriesX[0]:Scaled_BoxBoundriesX[1]] \n",
    "\n",
    "                    #print(\"chunked_BCRmap\",chunked_BCRmap)\n",
    "                    #print(\"chunked_LAKmap\",chunked_LAKmap)\n",
    "                    #showNPArrayAsImage(chunked_BCRmap, \"chunked_BCRmap\", \"gray\")\n",
    "                    #showNPArrayAsImage(chunked_LAKmap, \"LAKmap\", \"gray\")\n",
    "                    \n",
    "                    #Scale the values of the Arrays in a gaussian distrubution with mean 0 and diviation 1?!?!?!\n",
    "                    chunked_BCRmap, chunked_LAKmap = preprocessing.scale(chunked_BCRmap) , preprocessing.scale(chunked_LAKmap) \n",
    "\n",
    "                    #Normalize the Values betweeen -1...1\n",
    "                    chunked_BCRmap, chunked_LAKmap = preprocessing.normalize(chunked_BCRmap, norm='l1')  , preprocessing.normalize(chunked_LAKmap, norm='l1')  \n",
    "\n",
    "                    '''\n",
    "                    print(\"chunked_BCRmap\",chunked_BCRmap)\n",
    "                    print(\"chunked_LAKmap\",chunked_LAKmap)\n",
    "\n",
    "                    showNPArrayAsImage(chunked_BCRmap, \"chunked_BCRmap\", \"gray\")\n",
    "                    showNPArrayAsImage(chunked_LAKmap, \"LAKmap\", \"gray\")\n",
    "                    input()\n",
    "                    '''\n",
    "\n",
    "                    \n",
    "                    if it == -1:\n",
    "                        input(\"TEST ONCE del then  show chunked box, BCR, LAK\")\n",
    "                        showNPArrayAsImage(Chunks[i], \"Chunk[i]\", \"gray\")\n",
    "                        showNPArrayAsImage(chunked_BCRmap, \"chunked_BCRmap\", \"copper\")\n",
    "                        showNPArrayAsImage(chunked_LAKmap, \"chunked_LAKmap\", \"bone\")\n",
    "                        input()\n",
    "                    \n",
    "                    #index the BCR /LAK map to the right size \n",
    "                    CHUNKED_BoxCountR_SpacialLac_map_Dict[it] = [chunked_BCRmap, chunked_LAKmap]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                #Scale Dataset : Scaled data has zero mean and unit variance\n",
    "                Chunks[i]= preprocessing.scale(Chunks[i])\n",
    "\n",
    "                #Normalizing ARRAY  from 0...255 to -1...+1\n",
    "                Chunks[i] = preprocessing.normalize(Chunks[i], norm='l1')        \n",
    "\n",
    "                #Chunks[i] = Chunks[i].reshape(1,ChunkLenght , ChunkLenght )\n",
    "\n",
    "                #Chunkshape = (int(Chunks[i].shape[0]) , int(Chunks[i].shape[1]) )\n",
    "                Chunkshape = Chunks[i].shape\n",
    "\n",
    "                #Chunkshape = Chunks[0].shape    #The first CHunk should be the right size \n",
    "                # if Chunkshape is \n",
    "                if BoxBoundriesX[1] > npOutputFile.shape[1]  or BoxBoundriesY[1] > npOutputFile.shape[0]:\n",
    "                    print(\"Chunkshape and shape are Diffrent... reshaping\")\n",
    "                    Chunks[i] =  reshape_Data(Chunks[i], Chunkshape, shape)\n",
    "                    continue\n",
    "\n",
    "                assert Chunks[i].shape == original_shape\n",
    "                #showNPArrayAsImage(Chunks[i], \"feature\", \"gray\")\n",
    "\n",
    "\n",
    "                newshape = ( 1,int(original_shape[0]),int(original_shape[1]) )\n",
    "                Chunks[i] = np.reshape(Chunks[i], newshape)\n",
    "\n",
    "                #Chunks[i] = Chunks[i].astype(float)\n",
    "                \n",
    "\n",
    "                #saving test or Train image and label\n",
    "                #iterationForlabel = 2\n",
    "                feature =  Chunks[i]\n",
    "                label =  [np.array(CHUNKED_BoxCountR_SpacialLac_map_Dict[0]) , np.array(CHUNKED_BoxCountR_SpacialLac_map_Dict[1]) , np.array(CHUNKED_BoxCountR_SpacialLac_map_Dict[2]) , np.array(CHUNKED_BoxCountR_SpacialLac_map_Dict[3]) ]\n",
    "                #print(\"feature\",feature)\n",
    "                #print(\"label\",label)\n",
    "\n",
    "                if placingcondition == True:\n",
    "                    print(\"Placingcondition is true, Append Chunk to dataset\")\n",
    "\n",
    "                    #save\n",
    "                    trainsaveplace = FileParentPath+\"/Datasets/train/\"\n",
    "                    \n",
    "                    #saving image\n",
    "                    imagesaveplace = trainsaveplace+ \"/features/\"+\"Feature\"+ str(Num_train)\n",
    "                    np.save(imagesaveplace, feature)\n",
    "\n",
    "                    #saving label\n",
    "                    labelsaveplace = trainsaveplace+ \"/labels/\"+\"label\"+ str(Num_train)\n",
    "\n",
    "                    #CANT save List with diffrent sized np arrays with np.save -> use pickle as workaround\n",
    "                    pickle.dump(label,open(labelsaveplace,\"wb\"))\n",
    "                    #np.save(labelsaveplace, label)\n",
    "                    Num_train +=1\n",
    "                        \n",
    "                else:\n",
    "                    testsaveplace = FileParentPath+\"/Datasets/test/\"\n",
    "\n",
    "                    #saving image\n",
    "                    imagesaveplace = testsaveplace+ \"/features/\"+\"Feature\"+ str(Num_test)\n",
    "                    np.save(imagesaveplace, feature)\n",
    "\n",
    "                    #saving label\n",
    "                    labelsaveplace = testsaveplace+ \"/labels/\"+\"label\"+ str(Num_test)\n",
    "                    #np.save(labelsaveplace, label)\n",
    "                    #CANT save List with diffrent sized np arrays with np.save -> use pickle as workaround\n",
    "                    pickle.dump(label,open(labelsaveplace,\"wb\"))\n",
    "                    Num_test +=1\n",
    "\n",
    "\n",
    "\n",
    "                #After this Chunk set the new Borders of the new chunk for next turn\n",
    "\n",
    "                if BoxBoundriesX[1] < npOutputFile.shape[1]:\n",
    "                    # hat das boxende x noch nicht die volle XRange erreicht, so setze die box weiter sonst setze ihn wieder auf start und versetze ihn um y\n",
    "                    #print(\"move box into x direction\")\n",
    "                    #print(\"maxIndexX\",maxIndexX)\n",
    "                    BoxBoundriesX[0] =BoxBoundriesX[0] + maxIndexX\n",
    "                    BoxBoundriesX[1] = BoxBoundriesX[1] + maxIndexX\n",
    "                    #print(\"BoxBoundriesX\", BoxBoundriesX)\n",
    "                else:\n",
    "                    #print(BoxBoundriesY,\"BoxBoundriesY\")\n",
    "                    #BoxBoundriesX = VersetzeBoxZumStartX(BoxBoundriesX,iteration)\n",
    "                    print(\"move box into start x\")\n",
    "\n",
    "                    BoxBoundriesX[0]=0\n",
    "                    BoxBoundriesX[1]=maxIndexX\n",
    "                    #BoxBoundriesY = VersetzeBoxnachY(BoxBoundriesY, iteration)\n",
    "                    BoxBoundriesY[0]+=maxIndexY\n",
    "                    BoxBoundriesY[1]+=maxIndexY\n",
    "\n",
    "                    #print( \"Boxsize:\",boxsize ,\" Progress:\",indexY, \"of\",maxIndexY )\n",
    "                    #pbar.update(1)\n",
    "\n",
    "\n",
    "            end = time.time()     \n",
    "            print(round(end,1) - round(start,1), \"seconds passed for chunking and Make Train Data for 1 File\")\n",
    "\n",
    "        except :\n",
    "            PrintException()\n",
    "            input()\n",
    "            pass\n",
    "            #print(label, f, str(e))\n",
    "    \n",
    "    pbar.close()        #close the percentage bar cause all pictures have been processed\n",
    "\n",
    "    #To evaluate, if balancing happened  show figure of all BCR/LAKS of the training dataset\n",
    "    x,y = np.array([]) , np.array([])\n",
    "    for Koordinate in DensityMap:\n",
    "        x,y = np.append(x,Koordinate[0]) , np.append(y,Koordinate[1])\n",
    "    \n",
    "    # Plot\n",
    "    plt.scatter(x, y,s=1, alpha=0.33)\n",
    "    plt.title('Lacunarity-Boxcountratio Diagramm')\n",
    "    plt.xlabel('sumBCR')\n",
    "    plt.ylabel('MeanLAK')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"Num_train\",Num_train ,\"Num_test\",Num_test)\n",
    "    #return train_data, train_labels, test_data, test_labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if REBUILD_DATA == True:\n",
    "    delete_dataset_from_last_time()\n",
    "    make_train_test_data(shape)\n",
    "#REBUILDING/Balancing DATA DONE ---------------------------------------------------------------------------------------------\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create COUSTOM Pytorch DATASET with features and labels----------------------------------------------------------------------------\n",
    "# from: https://stackoverflow.com/questions/56774582/adding-custom-labels-to-pytorch-dataloader-dataset-does-not-work-for-custom-data\n",
    "\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "class Dataset:\n",
    "\n",
    "    def __init__(self, root):\n",
    "        \"\"\"Init function should not do any heavy lifting, but\n",
    "            must initialize how many items are availabel in this data set.\n",
    "        \"\"\"\n",
    "        self.featurepath = root + \"/features\"\n",
    "        self.labelpath = root + \"/labels\"\n",
    "\n",
    "        self.ROOT = root\n",
    "        self.featurelist = [f for f in listdir(self.featurepath) if isfile(join(self.featurepath, f))]\n",
    "        self.labellist = [f for f in listdir(self.labelpath) if isfile(join(self.labelpath, f))]\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"return number of points in our dataset\"\"\"\n",
    "        return len(self.featurelist)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\" Here we have to return the item requested by `idx`\n",
    "            The PyTorch DataLoader class will use this method to make an iterable for\n",
    "            our training or validation loop.\n",
    "        \"\"\"\n",
    "        imagepath =   self.featurepath+\"/\"+ \"Feature\" +str(idx)+\".npy\"\n",
    "        img = np.load(imagepath)\n",
    "\n",
    "        labelpath =   self.labelpath+\"/\"+ \"label\"+str(idx)\n",
    "        #label = np.load(labelpath)\n",
    "        #Below is to read and retrieve its contents, rb-read binary\n",
    "        with open(labelpath, \"rb\") as f:\n",
    "            label = pickle.load(f) \n",
    "            labels_2 = np.array(label[0])\n",
    "            labels_4 = np.array(label[1])\n",
    "            labels_8 = np.array(label[2])\n",
    "            labels_16 = np.array(label[3])\n",
    "        return img, labels_2 , labels_4 , labels_8, labels_16\n",
    "\n",
    "\n",
    "\n",
    "#And now, you can create an instance of this class as,\n",
    "trainDatasetSaveplace = FileParentPath + \"/Datasets/train\"\n",
    "trainDataset = Dataset(trainDatasetSaveplace)\n",
    "#Now, you can instantiate the DataLoader:\n",
    "trainDataloader = DataLoader(trainDataset, batch_size=opt.batch_size, shuffle=False, num_workers=2, drop_last=True)\n",
    "dataiter = iter(trainDataloader)\n",
    "trainDataset = dataiter.next()\n",
    "#trainDataset = trainDataset.numpy() # convert train_data to numpy for display\n",
    "trainDataset  = transforms.ToTensor()\n",
    "\n",
    "#DEFINING TEST DATA LOADER FOR TESTINGs\n",
    "\n",
    "testDatasetSaveplace = FileParentPath + \"/Datasets/test\"\n",
    "testDataset = Dataset(testDatasetSaveplace)\n",
    "testDataLoader = DataLoader(testDataset, batch_size=opt.batch_size, shuffle=False, num_workers=1, drop_last=True )\n",
    "#This will create batches of your data that you can access as:\n",
    "testiter=  iter(testDataLoader)\n",
    "testDataset = testiter.next()\n",
    "#testDataset = testDataset.numpy()\n",
    "testDataset  = transforms.ToTensor()\n",
    "\n",
    "\n",
    "#####################################################################################################################\n",
    "\n",
    "#\n",
    "#       DATA COMPLETE       ->     NOW MACHINE LEARNING PART\n",
    "#\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from FractalGANv3 import BoxCountEncoder # hast to be the new file script for this beleg...\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "previous_Best_Loss = None\n",
    "Loss_Now = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#INIT BoxcountNetParams as empty Dict\n",
    "BoxCountParameter = {}\n",
    "\n",
    "\n",
    "'''\n",
    "The BoxCountEncoder takes the image and calculates the boxcountratios and the Lakcountmaps for each iteration and passes all the arrays(iteration) into a dict and returns it.\n",
    "The BCmaps/LAKmaps can be calced via the cpu, so a picture with the corresponding BCR/LAK  gives the generated image a Style/content, that the generator takes with the latentvektor z to generate an image\n",
    "\n",
    "The BC Encoder Calculates all the maps of each scaling in one go, while the cpu version of the BC Encoder just can calc one scaling at a time. \n",
    "The BC Encoder is trained, to be usable in training of the whole FractalGAN alg without relying the cpu calcing the answer\n",
    "Test TIMEDIFFRENCE\n",
    "'''\n",
    "\n",
    "\n",
    "class BoxCountEncoder(nn.Module):\n",
    "    def __init__(self,Parameter):\n",
    "        super(BoxCountEncoder, self).__init__()\n",
    "\n",
    "        #Boxcount EncoderLayer<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
    "        #  Reduces the incoming latent vector and the BCR AND LAK MAPs by factor 2 and constraining the network forcing to forget and generalize------------------------------------------------\n",
    "\n",
    "        self.LayerDiscription = Parameter['BoxCountLayerDiscription']   #\n",
    "        self.input_shape = Parameter['input_shape']\n",
    "        self.LayerCount = len(self.LayerDiscription)\n",
    "        self.Layers = nn.ModuleList() \n",
    "        self.OutputLayerIndexList = Parameter['OutputLayerIndexList']\n",
    "        #print(\"self.OutputLayerIndexList\", self.OutputLayerIndexList)\n",
    "\n",
    "        #self.OutputActivation = []\n",
    "        #Throughput=[]   #list of layercount for Batchnormlayer\n",
    "        #ATTENTION  ENHANCER BUILDS NETWORK BACKWARDS AND IN AND OUT ARE ALSO SWITCHED\n",
    "        for i in range(self.LayerCount):        #iterate forwards\n",
    "            IN,OUT,Kx, Ky,Sx,Sy,Px,Py,BN = self.LayerDiscription[i]\n",
    "            #print(\"Layer\",i,\" with Parameters\", IN,OUT,Kx, Ky,Sx,Sy,Px,Py,BN)\n",
    "            self.Layers.append(nn.Conv2d(IN,OUT, kernel_size=(Kx, Ky), stride=(Sx, Sy), padding=(Px, Py)) )      #Attention Compressor INOUT NOrmal\n",
    "            \n",
    "            #if this is an output layer, then use Sigmoid instead of relu to prevent jumps for values around zero\n",
    "            #Inter3,OUTCOM ,1, 1,1,1,0,0,0\n",
    "            #if int(i) == int(self.LayerCount)-1:\n",
    "            if OUT==2 and  Kx==1 and Ky==1 and Sx==1 and Sy ==1 or  int(i) == int(self.LayerCount)-1: \n",
    "                #print(\"Output Layer found\")\n",
    "                #self.Layers.append(nn.Sigmoid())\n",
    "                self.Layers.append(nn.Tanh())\n",
    "                #Cause tanh is another layer it has to be in  self.OutputLayerIndexList, so it dosent connect to x but branched out to y\n",
    "                #self.OutputLayerIndexList.append(i)\n",
    "\n",
    "            else:\n",
    "                #Just use LeakyReLU for fast convergence\n",
    "                self.Layers.append(nn.LeakyReLU(inplace = True))\n",
    "            \n",
    "            if BN ==1:\n",
    "                self.Layers.append( nn.BatchNorm2d(OUT, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True) )      #Attention Compressor INOUT NOrmal\n",
    "                #Throughput.append(OUT)      \n",
    "\n",
    "        #for i in range(len(self.BatchNormLayers)) :\n",
    "        #    self.BatchNormLayers[i] =  nn.BatchNorm2d(Throughput[i], eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)          #affine = False -> Parameters will not be trained\n",
    "        \n",
    "        #print(\"self.input_shape\",self.input_shape)\n",
    "        #input()\n",
    "        \n",
    "        #n_size = get_conv_output(self, self.input_shape)\n",
    "        \n",
    "        #self.BoxCountR_SpacialLac_map_Dict = {}\n",
    "        print(self.Layers)\n",
    "        print(\"-------------INIT DONE ------------------\")\n",
    "\n",
    "    \n",
    "    #https://discuss.pytorch.org/t/inferring-shape-via-flatten-operator/138/2\n",
    "    # generate input sample and forward to get shape\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        #ATTENTION  ENHANCER BUILDS NETWORK BACKWARDS AND IN AND OUT ARE ALSO SWITCHED\n",
    "        #BatchNormlayer = 0\n",
    "\n",
    "        #BoxCountR_SpacialLac_map  = self.Conv_BOXCOUNT_features(x)\n",
    "        #print(\"self.OutputLayerIndexList\", self.OutputLayerIndexList)\n",
    "        output2, output4, output8, output16 = None, None, None, None\n",
    "        OutputList = [output2, output4, output8, output16]\n",
    "        outputindex = 0\n",
    "        for i, layer in enumerate(self.Layers):        #iterate forwards\n",
    "            #IN,OUT, Kx, Ky,Sx,Sy,Px,Py,BN = self.LayerDiscription[i]\n",
    "            #self.Layers[i] = nn.ConvTranspose2d(OUT, IN, kernel_size=(Kx, Ky), stride=(Sx, Sy), padding=(Px, Py))       #Attention ENhancer IN OUT Switched\n",
    "            #print(\"i\", i,\"####################################################\")\n",
    "            #print(\"BoxCountEncoder Layer\",i)\n",
    "            #print(layer)\n",
    "\n",
    "            if i in self.OutputLayerIndexList:      #If this is a Output layer\n",
    "                out = self.Layers[i](x)     # create branch and dont overwrite x\n",
    "                #print(\"Create Branch\")\n",
    "            elif i-1 in self.OutputLayerIndexList:      #If this is a Output layer ACTIVATION FUNCTION (tanh)\n",
    "                out = self.Layers[i](out)     # ACtivate out with act. fct\n",
    "                OutputList[outputindex] = out       # set value for each output-layer / scale \n",
    "                #print(\"Activate Branch for output\",outputindex)                \n",
    "                outputindex +=1 \n",
    "\n",
    "            else:\n",
    "                x = self.Layers[i](x)\n",
    "                #print(\"Append layer to Main Branch\")\n",
    "            #print(\"####################################################\")\n",
    "\n",
    "        #OutputList[outputindex] = x\n",
    "\n",
    "        #BCR_LAK_map_2 , BCR_LAK_map_4 , BCR_LAK_map_8 , BCR_LAK_map_16  = \n",
    "        OutputList[0] , OutputList[1] , OutputList[2] , OutputList[3] \n",
    "\n",
    "        #x = x.view(x.size(0),-1)\n",
    "        #print(x.size)\n",
    "\n",
    "\n",
    "        return OutputList[0] , OutputList[1] , OutputList[2] , OutputList[3]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def TrainSpacialBoxcount_with(HyperparameterAndENCODERCLASS):\n",
    "    HyperParameterspace, BoxCountEncoder =  HyperparameterAndENCODERCLASS \n",
    "\n",
    "    global previous_Best_Loss, Loss_Now\n",
    "    #BoxCountEncoder = None\n",
    "\n",
    "    #INIT VARIABLES\n",
    "    opt.n_epochs = HyperParameterspace['n_epochs']\n",
    "    opt.batch_size = HyperParameterspace['batch_size']\n",
    "    opt.lr = HyperParameterspace['lr']\n",
    "    opt.b1 = HyperParameterspace['b1']\n",
    "    opt.b2 = HyperParameterspace['b2']\n",
    "\n",
    "    #Attention Alg could learn to favour just one\n",
    "    Scalefactor_2  = HyperParameterspace['Scalefactor_2']\n",
    "    Scalefactor_4  = HyperParameterspace['Scalefactor_4']\n",
    "    Scalefactor_8  = HyperParameterspace['Scalefactor_8']\n",
    "    Scalefactor_16  =  1.0 - Scalefactor_2 - Scalefactor_4 - Scalefactor_8  # Sum has to be 1, else hyperopt just choose low multipliers like 0.01 to lower loss\n",
    "\n",
    "    #BoxCountLayerDiscription\n",
    "    #\n",
    "    #self.BoxcountRatioConv = nn.Conv2d(3, 16, (self.BoxsizeX,BoxsizeY), (len(self.BoxsizeX), len(self.BoxsizeY) ), padding=0) \n",
    "    #self.LACcountConv = nn.Conv2d(3, 16, (self.BoxsizeX,self.BoxsizeY), (len(self.BoxsizeX), len(self.BoxsizeY) ), padding=0) \n",
    "\n",
    "    Boxsize=[2,4,8,16,32,64,128,256,512,1024]\n",
    "\n",
    "\n",
    "    #Channles\n",
    "    IN, OUTCOM = 1 , 2      #Channels 2, cause output is BCRmap and LAKmap, one is derived from the other\n",
    "    Inter1, Inter2, Inter3    = HyperParameterspace['Inter1'], HyperParameterspace['Inter2'], HyperParameterspace['Inter3']          # Hyperoptimization here\n",
    "\n",
    "    #Kernelsize in X/Y resprective layer is 2, cause...\n",
    "    Kx1, Kx2, Kx3, Kx4              = 2,2,2,2       \n",
    "    Ky1, Ky2, Ky3, Ky4              = 2,2,2,2\n",
    "    # ...with a stride of 2 the picture is getting halfed in size, exacly like the boxcounting with bigger boxsizes , but in cpu version the ori bz overlap one pixel, which here is not checkk\n",
    "    Sx1, Sx2, Sx3, Sx4              = 2, 2, 2, 2\n",
    "    Sy1, Sy2, Sy3, Sy4              = 2, 2, 2, 2\n",
    "    #padding should be 0, cause every picture is same size and all the kernels fit perfectly\n",
    "    Px1, Px2, Px3, Px4              = 0,0,0,0\n",
    "    Py1, Py2, Py3, Py4              = 0,0,0,0\n",
    "    #Batchnorm is not needed, causewe want to focus just on the convolution calculation  and dont want to alter the image/ entry arrays in any unknown form... EVALUATE and CHECK \n",
    "    BN1, BN2, BN3, BN4              = 0,0,0,0\n",
    "\n",
    "    #Intermediate OutputLayer ... Cause every Filter of a Convulution  is described within the Channels in the hidden layers and we want to output the BCR and LAK like like the cpu version...\n",
    "    # we have to generate an output with a 1x1 = KxS conv with x Chan input and 2 Chan Output for calcing the loss\n",
    "\n",
    "\n",
    "\n",
    "    BoxCountLayerDiscription = [    [IN,    Inter1,Kx1, Ky1,Sx1,Sy1,Px1,Py1,BN1],   #input layer\n",
    "                                    [Inter1,OUTCOM ,1, 1,1,1,0,0,0],                # output layer for first iteration (Boxsize 2)\n",
    "\n",
    "                                    [Inter1,Inter2,Kx2, Ky2,Sx2,Sy2,Px2,Py2,BN2],\n",
    "                                    [Inter2,OUTCOM ,1, 1,1,1,0,0,0],                # output layer for second iteration (Boxsize 4)\n",
    "        \n",
    "                                    [Inter2,Inter3,Kx3, Ky3,Sx3,Sy3,Px3,Py3,BN3],\n",
    "                                    [Inter3,OUTCOM ,1, 1,1,1,0,0,0],                # output layer for third iteration (Boxsize 8)\n",
    "\n",
    "                                    [Inter3,OUTCOM,Kx4, Ky4,Sx4,Sy4,Px4,Py4,BN4],   #last ouput layer\n",
    "                                            ]                       # [Inter3,OUTCOM ,1, 1,1,1,0,0,0],                # output layer for 4th iteration (Boxsize 16)\n",
    "\n",
    "    input_shape = (opt.batch_size,1, ChunkLenght,ChunkLenght)\n",
    "\n",
    "    OutputLayerIndexList = [2,6,10,12]        # Cause the intermediate output layers are branched out from the main flowchart\n",
    "\n",
    "    BoxCountNetParameters = {'BoxCountLayerDiscription': BoxCountLayerDiscription, 'input_shape': input_shape, 'OutputLayerIndexList': OutputLayerIndexList}\n",
    "\n",
    "\n",
    "    Modelname =  \"n_epochs_\" + str(round(opt.n_epochs,3)) \n",
    "    Modelname += \"_batch-size_\" + str(round(opt.batch_size,3))   \n",
    "    Modelname += \"_learning-rate_\" + str(round(opt.lr,3))\n",
    "    Modelname += \"_beta-decay_\" + str(round(opt.b1,3)) +\"_\" + str(round(opt.b2,3))\n",
    "\n",
    "    Modelname += \"_Scalefactors_\" + str(round(Scalefactor_2,3)) +\"_\" + str(round(Scalefactor_4,3)) +\"_\" + str(round(Scalefactor_8,3))\n",
    "\n",
    "\n",
    "\n",
    "    # -----------------\n",
    "    #  Train_BoxcountingCONV\n",
    "    # -----------------\n",
    "\n",
    "    #define Loss\n",
    "    pixelwise_loss = torch.nn.L1Loss()\n",
    "\n",
    "    #Init BoxcountEncoder\n",
    "    BoxCountEncoder = BoxCountEncoder(BoxCountNetParameters)\n",
    "\n",
    "\n",
    "    BoxCountEncoder.to(device)\n",
    "    pixelwise_loss.to(device)\n",
    "\n",
    "    # Optimizers\n",
    "    optimizer_BC = torch.optim.Adam(BoxCountEncoder.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "\n",
    "    if device==\"cuda\":\n",
    "        Tensor = torch.cuda.FloatTensor \n",
    "\n",
    "        BoxCountEncoder.to(device)\n",
    "        pixelwise_loss.to(device)\n",
    "\n",
    "        BoxCountEncoder.cuda()\n",
    "        pixelwise_loss.cuda() \n",
    "\n",
    "    else:\n",
    "        Tensor = torch.FloatTensor\n",
    "\n",
    "    from tqdm import tqdm\n",
    "\n",
    "    # ----------\n",
    "    #  Training\n",
    "    # ----------\n",
    "\n",
    "    epochs =range(opt.n_epochs)\n",
    "\n",
    "    print(\"Model: \",Modelname)\n",
    "\n",
    "    for epoch in tqdm(epochs):\n",
    "\n",
    "        #print(\"epoch \",str(epoch), \"of\", str(opt.n_epochs) )\n",
    "        for i, (images, labels_2, labels_4, labels_8, labels_16 ) in enumerate(trainDataloader):\n",
    "            #real_labels_2, real_labels_4, real_labels_8, real_labels_16 = labels\n",
    "            \n",
    "            #print(\"Nr\",str(i) ,\"of\", str(len(trainDataloader)))\n",
    "            real_labels_2 = Variable(labels_2.type(Tensor))\n",
    "            real_labels_2.to(device)\n",
    "\n",
    "            real_labels_4 = Variable(labels_4.type(Tensor))\n",
    "            real_labels_4.to(device)\n",
    "\n",
    "            real_labels_8 = Variable(labels_8.type(Tensor))\n",
    "            real_labels_8.to(device)\n",
    "\n",
    "            real_labels_16 = Variable(labels_16.type(Tensor))\n",
    "            real_labels_16.to(device)\n",
    "\n",
    "            # Configure input\n",
    "            real_imgs = Variable(images.type(Tensor))\n",
    "            real_imgs.to(device)\n",
    "\n",
    "            optimizer_BC.zero_grad()\n",
    "\n",
    "            BCR_LAK_map_2 , BCR_LAK_map_4 , BCR_LAK_map_8 , BCR_LAK_map_16 = BoxCountEncoder(real_imgs)\n",
    "\n",
    "\n",
    "            BCR_LAK_map_2_loss  = pixelwise_loss(BCR_LAK_map_2, real_labels_2)\n",
    "            BCR_LAK_map_4_loss = pixelwise_loss(BCR_LAK_map_4, real_labels_4)\n",
    "            BCR_LAK_map_8_loss = pixelwise_loss(BCR_LAK_map_8, real_labels_8)\n",
    "            BCR_LAK_map_16_loss = pixelwise_loss(BCR_LAK_map_16, real_labels_16)\n",
    "            #Scalefactor_2 , Scalefactor_4 , Scalefactor_8 , Scalefactor_16  =  0.25, 0.25, 0.25 , 0.25      # maybe optimiziing usage?!\n",
    "            #assert Scalefactor_2 + Scalefactor_4 + Scalefactor_8 + Scalefactor_16 == 1.0\n",
    "\n",
    "            BCR_LAK_loss =  Scalefactor_2 * BCR_LAK_map_2_loss + Scalefactor_4 * BCR_LAK_map_4_loss + Scalefactor_8 * BCR_LAK_map_8_loss + Scalefactor_16 * BCR_LAK_map_16_loss\n",
    "            #print(\"loss: BCR_LAK_loss\",BCR_LAK_loss)\n",
    "\n",
    "            #input()\n",
    "            BCR_LAK_loss.backward()\n",
    "            optimizer_BC.step()\n",
    "        \n",
    "        print(\n",
    "            \"[Epoch %d/%d] [Batch %d/%d] [BC loss: %f]  \"\n",
    "            % (epoch, opt.n_epochs, i, len(trainDataloader), BCR_LAK_loss.item() )\n",
    "        )\n",
    "\n",
    "\n",
    "    ### SAVE MODEL IF its better than 0something\n",
    "    if previous_Best_Loss == None:\n",
    "        previous_Best_Loss = BCR_LAK_loss.item()\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "    Loss_Now = BCR_LAK_loss.item()\n",
    "\n",
    "\n",
    "    if Loss_Now <= previous_Best_Loss:\n",
    "        #<= to save first model always and then just, when better model was found with LOWER LOSS \n",
    "        saveplace = FileParentPath\n",
    "        saveplace +=\"/models/\"\n",
    "        saveplace += \"Loss\" + str(round(BCR_LAK_loss.item(),3)) +\"---\"\n",
    "        saveplace += Modelname\n",
    "        NetParametersSaveplace = saveplace +\".netparams\"\n",
    "        with open(NetParametersSaveplace, \"wb\") as f:\n",
    "            pickle.dump(BoxCountNetParameters, f)\n",
    "        \n",
    "        saveplace += \".model\"\n",
    "        torch.save(BoxCountEncoder.state_dict(), saveplace)\n",
    "        #only update, when it was higher\n",
    "        previous_Best_Loss = Loss_Now\n",
    "\n",
    "        #model.save(saveplace)\n",
    "\n",
    "    else:\n",
    "        print(\"Score was lower than before\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return {'loss': BCR_LAK_loss.item(), 'status': STATUS_OK}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "youwanttotrain = input(\"Do you want to train? Y/n\")\n",
    "\n",
    "if youwanttotrain == \"\" or youwanttotrain == \"y\" or youwanttotrain == \"Y\":\n",
    "\n",
    "\n",
    "    #To save trials object to pick up where you left\n",
    "    def run_trials(HyperParameterspace, Modelname):\n",
    "        TrialsSaveplace = FileParentPath\n",
    "        TrialsSaveplace +=  \"/\"+ str(Modelname) +\".hyperopt\" \n",
    "        trials_step = 1  # how many additional trials to do after loading saved trials. 1 = save after iteration\n",
    "        max_trials = 3  # initial max_trials. put something small to not have to wait\n",
    "\n",
    "        \n",
    "        try:  # try to load an already saved trials object, and increase the max\n",
    "            trials = pickle.load(open(TrialsSaveplace, \"rb\"))\n",
    "            print(\"Found saved Trials! Loading...\")\n",
    "            max_trials = len(trials.trials) + trials_step\n",
    "            print(\"Rerunning from {} trials to {} (+{}) trials\".format(len(trials.trials), max_trials, trials_step))\n",
    "        except:  # create a new trials object and start searching\n",
    "            trials = Trials()\n",
    "\n",
    "        #best = fmin(fn=mymodel, space=model_space, algo=tpe.suggest, max_evals=max_trials, trials=trials)\n",
    "        \n",
    "        best = fmin(TrainSpacialBoxcount_with, HyperparameterAndENCODERCLASS, algo=tpe.suggest, max_evals=max_trials, trials=trials)\n",
    "\n",
    "        print(\"Best:\", best)\n",
    "        \n",
    "        # save the trials object\n",
    "        with open(TrialsSaveplace, \"wb\") as f:\n",
    "            pickle.dump(trials, f)\n",
    "\n",
    "\n",
    "    HyperParameterspace = {\n",
    "        'n_epochs':hp.choice('opt.n_epochs', range(5,150,5) ),\n",
    "        'batch_size':hp.choice('opt.batch_size', [2,4,8,16,32,64,128,256,512] ),\n",
    "        'lr':hp.uniform('lr', 0.0000001 , 0.1 ),\n",
    "        'b1':hp.uniform('b1', 0.01 , 1.0 ),\n",
    "        'b2':hp.uniform('b2', 0.01 , 1.0 ),\n",
    "        'Inter1':hp.choice('Inter1', range(1,512) ),\n",
    "        'Inter2':hp.choice('Inter2', range(1,512) ),\n",
    "        'Inter3':hp.choice('Inter3', range(1,512) ),\n",
    "        'Scalefactor_2':hp.uniform('Scalefactor_2', 0.4, 0.5 ),   #Dont care alot about scaling factor 2, cause it's dim reduction is not substantial to be an encoder, so 0.01 is allowed\n",
    "        'Scalefactor_4':hp.uniform('Scalefactor_4', 0.15, 0.25 ),\n",
    "        'Scalefactor_8':hp.uniform('Scalefactor_8', 0.1, 0.15 ),\n",
    "\n",
    "    }     \n",
    "\n",
    "    HyperparameterAndENCODERCLASS = HyperParameterspace,BoxCountEncoder\n",
    "\n",
    "    print(\"Begin HyperparameterOptimization\")\n",
    "\n",
    "    # loop indefinitely and stop whenever you like\n",
    "\n",
    "    #TotalTrials = 0 \n",
    "    MaxTrys = 100\n",
    "    for TotalTrials in tqdm(range(MaxTrys)):\n",
    "        Modelname = \"SpacialBoxcountEncoder\"+\"_trialsOBJ\"\n",
    "        run_trials(HyperparameterAndENCODERCLASS, \"BoxcountEncoder\")    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from FractalGANv3 import BoxCountEncoder\n",
    "#import asyncio\n",
    "\n",
    "def TestSpacialBoxcount_with(Modelname, BoxCountEncoder):\n",
    "        \n",
    "    NetParametersSaveplace =FileParentPath+ \"/models/\"+ Modelname +\".netparams\"\n",
    "    BoxCountNetParameters = pickle.load(open(NetParametersSaveplace, \"rb\"))\n",
    "\n",
    "    saveplace = FileParentPath+ \"/models/\"+Modelname +\".model\"\n",
    "    \n",
    "    \n",
    "    device = \"cuda\"\n",
    "    #load and init the BCencoder\n",
    "    BoxCountEncoder = BoxCountEncoder(BoxCountNetParameters)\n",
    "    BoxCountEncoder.load_state_dict(torch.load(saveplace, map_location=device))\n",
    "    BoxCountEncoder.eval()\n",
    "\n",
    "\n",
    "\n",
    "    # ----------\n",
    "    #  Testing BoxcountEncoder\n",
    "    # ----------\n",
    "    \n",
    "    #define Loss\n",
    "    pixelwise_loss = torch.nn.L1Loss()\n",
    "\n",
    "    #Init BoxcountEncoder\n",
    "    #BoxCountEncoder = BoxCountEncoder(BoxCountNetParameters)\n",
    "\n",
    "\n",
    "    BoxCountEncoder.to(device)\n",
    "    pixelwise_loss.to(device)\n",
    "\n",
    "    # Optimizers\n",
    "    optimizer_BC = torch.optim.Adam(BoxCountEncoder.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
    "\n",
    "    #device = \"cpu\"\n",
    "\n",
    "    if device==\"cuda\":\n",
    "        Tensor = torch.cuda.FloatTensor \n",
    "\n",
    "        BoxCountEncoder.to(device)\n",
    "        pixelwise_loss.to(device)\n",
    "\n",
    "        BoxCountEncoder.cuda()\n",
    "        pixelwise_loss.cuda() \n",
    "\n",
    "    else:\n",
    "        Tensor = torch.FloatTensor\n",
    "\n",
    "        BoxCountEncoder.to(device)\n",
    "        pixelwise_loss.to(device)\n",
    "\n",
    "\n",
    "    #Begin testing by evaluating the test data set\n",
    "    for  i, (images, labels_2, labels_4, labels_8, labels_16 )  in enumerate(testDataLoader):\n",
    "        start = time.time()\n",
    "\n",
    "        torch.no_grad() \n",
    "\n",
    "        # Configure input\n",
    "        real_imgs = Variable(images.type(Tensor))\n",
    "        #print(\"real_imgs\",real_imgs)\n",
    "\n",
    "        real_imgs.to(device)\n",
    "\n",
    "        real_labels_2 = Variable(labels_2.type(Tensor))\n",
    "        real_labels_2.to(device)\n",
    "\n",
    "        real_labels_4 = Variable(labels_4.type(Tensor))\n",
    "        real_labels_4.to(device)\n",
    "\n",
    "        real_labels_8 = Variable(labels_8.type(Tensor))\n",
    "        real_labels_8.to(device)\n",
    "\n",
    "        real_labels_16 = Variable(labels_16.type(Tensor))\n",
    "        real_labels_16.to(device)\n",
    "\n",
    "\n",
    "        BCR_LAK_map_2 , BCR_LAK_map_4 , BCR_LAK_map_8 , BCR_LAK_map_16 = BoxCountEncoder(real_imgs)\n",
    "\n",
    "        optimizer_BC.zero_grad()\n",
    "\n",
    "        #encoded_imgs = BoxCountEncoder(real_imgs)\n",
    "\n",
    "        NumpyencImg2 =  BCR_LAK_map_2.cpu().detach().numpy()\n",
    "        NumpyencImg4 =  BCR_LAK_map_4.cpu().detach().numpy()\n",
    "        NumpyencImg8 =  BCR_LAK_map_8.cpu().detach().numpy()\n",
    "        NumpyencImg16 =  BCR_LAK_map_16.cpu().detach().numpy()\n",
    "        \n",
    "        '''\n",
    "\n",
    "        async def detachtask(inputtensor):\n",
    "            result = inputtensor.cpu().detach().numpy()\n",
    "            print(\"detached\")\n",
    "            return result\n",
    "        \n",
    "        async def getANDvisualize_Output(BCR_LAK_map_2,BCR_LAK_map_4, BCR_LAK_map_8, BCR_LAK_map_16):\n",
    "                        \n",
    "            NumpyencImg2 =  loop.create_task(detachtask(BCR_LAK_map_2))\n",
    "            NumpyencImg4 =  loop.create_task(detachtask(BCR_LAK_map_4))\n",
    "            NumpyencImg8 =  loop.create_task(detachtask(BCR_LAK_map_8))\n",
    "            NumpyencImg16 = loop.create_task(detachtask(BCR_LAK_map_16))\n",
    "            \n",
    "            #reallable2cpu = real_labels_2.cpu().detach().numpy()\n",
    "            #reallable4cpu = real_labels_4.cpu().detach().numpy()\n",
    "            #reallable8cpu = real_labels_8.cpu().detach().numpy()\n",
    "            #reallable16cpu = real_labels_16.cpu().detach().numpy()\n",
    "\n",
    "\n",
    "            #print(\"reallable8cpu\", reallable8cpu)\n",
    "            #oriimagecpu =  images.cpu().detach().numpy()\n",
    "\n",
    "            await asyncio.wait([NumpyencImg2, NumpyencImg4, NumpyencImg8, NumpyencImg16])   #, reallable4cpu, reallable8cpu, reallable16cpu ])\n",
    "            \n",
    "            return NumpyencImg2, NumpyencImg4, NumpyencImg8, NumpyencImg16\n",
    "            \n",
    "        try:\n",
    "            loop = asyncio.get_event_loop()\n",
    "            loop.set_debug(1)\n",
    "            NumpyencImg2, NumpyencImg4, NumpyencImg8, NumpyencImg16 = loop.run_until_complete(getANDvisualize_Output(BCR_LAK_map_2,BCR_LAK_map_4, BCR_LAK_map_8, BCR_LAK_map_16))\n",
    "        except:\n",
    "            PrintException()\n",
    "        finally:      \n",
    "        '''\n",
    "\n",
    "        showNPArrayAsImage(images[0,0,:,:], \"images[0]\", \"gray\")\n",
    "\n",
    "        #Show Output\n",
    "        print(\"showing first element of batch\")\n",
    "        #showNPArrayAsImage(NumpyencImg2[0,0,:,:], \"encoded_BCR_BZ2\", \"gray\")\n",
    "        showNPArrayAsImage(labels_2[0,0,:,:], \"real_BCR_2[0]\", \"gray\")\n",
    "\n",
    "\n",
    "        showNPArrayAsImage(NumpyencImg4[0,0,:,:], \"encoded_BCR_BZ4\", \"gray\")\n",
    "        showNPArrayAsImage(labels_4[0,0,:,:], \"real_BCR_4[0]\", \"gray\")\n",
    "\n",
    "\n",
    "        showNPArrayAsImage(NumpyencImg8[0,0,:,:], \"encoded_BCR_BZ8\", \"gray\")\n",
    "        showNPArrayAsImage(labels_8[0,0,:,:], \"real_BCR_8[0]\", \"gray\")\n",
    "\n",
    "\n",
    "        showNPArrayAsImage(NumpyencImg16[0,0,:,:], \"encoded_BCR_BZ16\", \"gray\")\n",
    "        showNPArrayAsImage(labels_16[0,0,:,:], \"real_BCR_16[0]\", \"gray\")\n",
    "\n",
    "\n",
    "        showNPArrayAsImage(NumpyencImg2[0,1,:,:], \"encoded_LAC_BZ2\", \"gray\")\n",
    "        showNPArrayAsImage(labels_2[0,1,:,:], \"real_LAC_2\", \"gray\")\n",
    "\n",
    "\n",
    "        showNPArrayAsImage(NumpyencImg4[0,1,:,:], \"encoded_LAC_BZ4\", \"gray\")\n",
    "        showNPArrayAsImage(labels_4[0,1,:,:], \"real_LAC_4\", \"gray\")\n",
    "\n",
    "\n",
    "        showNPArrayAsImage(NumpyencImg8[0,1,:,:], \"encoded_LAC_BZ8\", \"gray\")\n",
    "        showNPArrayAsImage(labels_8[0,1,:,:], \"real_LAC_8\", \"gray\")\n",
    "\n",
    "\n",
    "        showNPArrayAsImage(NumpyencImg16[0,1,:,:], \"encoded_LAC_BZ16\", \"gray\")\n",
    "        showNPArrayAsImage(labels_16[0,1,:,:], \"real_LAC_16\", \"gray\")\n",
    "\n",
    "        #print(\"NumpyencImg\", NumpyencImg)\n",
    "\n",
    "        #loop.close()\n",
    "        \n",
    "        end = time.time()\n",
    "\n",
    "            \n",
    "        BCR_LAK_map_2_loss  = pixelwise_loss(BCR_LAK_map_2, real_labels_2)\n",
    "        BCR_LAK_map_4_loss = pixelwise_loss(BCR_LAK_map_4, real_labels_4)\n",
    "        BCR_LAK_map_8_loss = pixelwise_loss(BCR_LAK_map_8, real_labels_8)\n",
    "        BCR_LAK_map_16_loss = pixelwise_loss(BCR_LAK_map_16, real_labels_16)\n",
    "        Scalefactor_2 , Scalefactor_4 , Scalefactor_8 , Scalefactor_16  =  0.25, 0.25, 0.25 , 0.25      # maybe optimiziing usage?!\n",
    "        assert Scalefactor_2 + Scalefactor_4 + Scalefactor_8 + Scalefactor_16 == 1.0\n",
    "\n",
    "        BCR_LAK_loss =  Scalefactor_2 * BCR_LAK_map_2_loss + Scalefactor_4 * BCR_LAK_map_4_loss + Scalefactor_8 * BCR_LAK_map_8_loss + Scalefactor_16 * BCR_LAK_map_16_loss\n",
    "        \n",
    "\n",
    "        BCR_LAK_loss.backward()\n",
    "        optimizer_BC.step()\n",
    "\n",
    "        \n",
    "        print(\n",
    "            \"[Batch %d/%d] [BC loss: %f] \"\n",
    "            % ( i, len(testDataLoader), BCR_LAK_loss.item())\n",
    "        )\n",
    "        print(end-start, \" seconds for boxcounting 1 file with batch_size of\",opt.batch_size )\n",
    "        input(\"presskey fornext batch\")\n",
    "        #batches_done = epoch * len(testDataLoader) + i\n",
    "\n",
    "        #sample_image(n_row=10, batches_done=batches_done)\n",
    "\n",
    "    return {'loss': BCR_LAK_loss.item(), 'status': STATUS_OK}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" #To disable GPU!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "youwanttotest = input(\"Do you want to test? Y/n\")\n",
    "\n",
    "if youwanttotest == \"\" or youwanttotest == \"y\" or youwanttotest == \"Y\":\n",
    "    #Modelname = \"CombinedLoss0.331---n_epochs_65_batch-size_16_learning-rate_0.049_beta-decay_0.78_0.821_Scalefactors_0.232_0.143_0.107\"\n",
    "    #Modelname = \"CombinedLoss1.145---n_epochs_145_batch-size_512_learning-rate_0.094_beta-decay_0.431_0.348_Scalefactors_0.077_0.182_0.119\"\n",
    "    #Modelname = \"Loss0.655---n_epochs_35_batch-size_128_learning-rate_0.021_beta-decay_0.581_0.574_Scalefactors_0.186_0.166_0.116\"\n",
    "    Modelname = \"Loss0.028---n_epochs_110_batch-size_32_learning-rate_0.001_beta-decay_0.283_0.996_Scalefactors_0.207_0.191_0.249\"\n",
    "    Modelname = \"Loss0.017---n_epochs_115_batch-size_64_learning-rate_0.002_beta-decay_0.412_0.593_Scalefactors_0.491_0.238_0.118\"\n",
    "    loss = TestSpacialBoxcount_with(Modelname,BoxCountEncoder)\n",
    "\n",
    "    #print(\"so time for 1 file would be\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results and discussion\n",
    "\n",
    "blablabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "lkalsdnfhaolikshjdas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
